{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Material adapted from Toke Faurby's and Chris Carvelli's)\n",
    "\n",
    "# Convolutional Neural networks 101\n",
    "\n",
    "\n",
    "Convolutional neural networks (or ConvNets) are a very succesfull type of neural networks, and are an integral part of reigniting the interest in neural networks.\n",
    "They are able to extract structural relations in the data such as spatial in images or temporal in time series.\n",
    "\n",
    "In this lab you will learn what *convolutional layers* are and how they work, as well as important related concepts such as *padding*, *stride*, and *pooling*.\n",
    "\n",
    "#### External resources:\n",
    "For an indept tutorial please see [stanford cs231n](http://cs231n.github.io/convolutional-networks/) or to read more see [Michael Nielsen](http://neuralnetworksanddeeplearning.com/chap6.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are convolutional networks?\n",
    "\n",
    "ConvNets are in may respects very similar to the dense feedforward networks we saw previously:\n",
    " * The network is still organized into layers\n",
    " * Each layer is parameterized by weights and biases\n",
    " * Each layer has an element-wise non-linear transformation (activation function)\n",
    " * There are no cycles in the connections (e.g.: [Recurrent Neural Networks](https://www.ibm.com/cloud/learn/recurrent-neural-networks) have cycles. They are very useful for processing sequential data, but we are not talking about them during the course)\n",
    "\n",
    "*So what is the difference?*\n",
    "The networks we saw previously are called *dense* because each unit receives input from all the units in the previous layer.\n",
    "This is not the case for ConvNets.\n",
    "In ConvNets each unit is only connected to a small subset of the input units.\n",
    "This is called the *receptive field* of the unit.\n",
    "\n",
    "#### Let us look at a quick example.\n",
    "Let us define a `3x3` window with the kernel weights (indicated by red in the bottom right).\n",
    "We apply the window by performning elementwise multiplication, and then summing the results, as shown in this animation:\n",
    "\n",
    "![](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)\n",
    "[GIF courtesy of [Stanford](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)]\n",
    "\n",
    "After having convolved the image we perform an elementwise non-linear transformation on the *convolved features*.\n",
    "In this example the input is a 2D *feature map* with depth 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strides, padding, and pooling\n",
    "\n",
    "Two important concepts for ConvNets are *strides* and *padding*.\n",
    "### Padding\n",
    "describes what we do at the edges of the feature map.\n",
    "If we don't use padding the feature map will get smaller every time, as we can see above. \n",
    "If we do use padding we can maintain the same resolution. \n",
    "In deep learning we generally just pad with zeros.\n",
    "In the example below in the '_Padding, no strides_' GIF we maintain the size by padding with one row/column of zeros on all sides.\n",
    "\n",
    "\n",
    "### Strides\n",
    "describe how far the window is moved each time. Strides can be used to reduce the size of the feature map, and the number of computations that needs to be performed.\n",
    "\n",
    "Strides and pooling (examples from [here](https://github.com/vdumoulin/conv_arithmetic#convolution-animations)) are shown in the table below.\n",
    "Notice how the output (green) changes shape.\n",
    "\n",
    "| ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif) | ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides.gif) | ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_strides.gif) | ![](https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides.gif) |\n",
    "|--------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| No padding, no strides                                                                     | Padding, no strides                                                                          | No padding, stride of 2                                                                 | Padding, stride of 2                                                                 |\n",
    "\n",
    "\n",
    "### Pooling\n",
    "is another method for reducing the spatial resolution. Similar to convolutional layers it works by sliding a window accross the feature map. Unlike the convolutional layers there are no learnable parameters, and the pooling layers perform the same simple operation every time. The most common types of pooling are:\n",
    " * *Max pooling* where the output of the pooling operation is the highest value in the window, and\n",
    " * *Mean pooling* which outputs the mean of the elements in the window.\n",
    " \n",
    "![Max pooling image](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Max_pooling.png/471px-Max_pooling.png)\n",
    "[Image courtesy of [Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Tensorflow\n",
    "- CPU: Just run *pip install tensorflow*\n",
    "- GPU Support: It's more complicated, follow [this video](https://www.youtube.com/watch?v=hHWkvEcDBO0). Please wait for the lab session to end and give priority to working on the exercise and ask questions before installing. Today's exercise does not require super-heavy calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependancies and supporting functions by running the code block below.\n",
    "from __future__ import absolute_import, division, print_function \n",
    "\n",
    "# import time\n",
    "# import sys, os\n",
    "\n",
    "%matplotlib inline\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "# from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"You are not using the GPU version of TF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load data\n",
    "data_set = keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train_),(x_test, y_test_) = data_set.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize data to [0, 1] interval\n",
    "\n",
    "y_train = OneHotEncoder(categories='auto', sparse=False).fit_transform(y_train_)\n",
    "y_test = OneHotEncoder(categories='auto', sparse=False).fit_transform(y_test_)\n",
    "\n",
    "## Print dataset statistics and visualize\n",
    "print(\"\"\"Information on dataset\n",
    "----------------------\"\"\")\n",
    "print(\"Training data shape:\\t\", x_train.shape, y_train.shape)\n",
    "print(\"Test data shape\\t\\t\",     x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a few MNIST examples\n",
    "img_to_show = 5\n",
    "idx = 0\n",
    "canvas = np.zeros((32*img_to_show, img_to_show*32, 3))\n",
    "print('\\nLabels')\n",
    "for i in range(img_to_show):\n",
    "    for j in range(img_to_show):\n",
    "        canvas[i*32:(i+1)*32, j*32:(j+1)*32] = x_train[idx] #mnist_data.train.images[idx].reshape((28, 28))\n",
    "        print(y_train_[idx], end=', ')\n",
    "        idx += 1\n",
    "    print()\n",
    "\n",
    "print('\\nInput data')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(canvas)\n",
    "plt.title('Example data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Getting use to Convolutional Networks\n",
    "\n",
    "In this first part you should experiment a bit, and get used to working with convolutional networks.\n",
    "\n",
    "You task is:\n",
    "\n",
    "1) Create a convolutional neural network, using both `Conv2D`, `MaxPooling2D` layers, with the following shapes:\n",
    "\n",
    "    (None, 32, 32, 3) [input]\n",
    "    (None, 16, 16, 16)\n",
    "    (None, 7, 7, 32)\n",
    "    (None, 5, 5, 64)\n",
    "    (None, 2, 2, 64)\n",
    "    (None, 1, 1, 128)\n",
    "\n",
    "2) How many trainable parameters parameters does this network have?\n",
    " * `keras.model.summary` is an easy way to see the number of parameters.\n",
    "\n",
    "\n",
    "3) Create a dense network with (roughly) the same number of parameters, and compare the summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_model = keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer((32, 32, 3)),\n",
    "    \n",
    "    keras.layers.Conv2D(16, (3,3), strides=(2,2), padding='same'),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(?, (?,?), strides=(?,?), padding='valid'),## YOUR CODE HERE!\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(?, (?,?), strides=(?,?), padding=?),## YOUR CODE HERE!\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.MaxPooling2D(pool_size=(?, ?), strides=(?,?), padding=?),## YOUR CODE HERE!\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(?, (?,?), strides=(?,?), padding=?),## YOUR CODE HERE!\n",
    "    keras.layers.Activation('relu'),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = None ## YOUR CODE HERE!\n",
    "\n",
    "\n",
    "\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: \n",
    "\n",
    "Now we want to compare the performance of dense and convolutional networks, and conduct some experiments.\n",
    "\n",
    "Your task\n",
    "\n",
    "1. Go back to Task 1, and update the networks such that they work (e.g. have non-linearities, and a soft-max output layer)\n",
    "1. Finish the code below, and compare the performance of the convolutional and dense network.\n",
    "1. For the remainder of the time try setting up hypothesies, and test them\n",
    " * How large does the dense network need to be in order to get similar performance as the convolutional?\n",
    " * When does an un-regularized convolutional network begin to overfit the data?\n",
    "\n",
    "___\n",
    "**Tip:** It might make sense to experiment with a reduced data set.\n",
    "You can remove observations, all occurances of some classes, or use a smaller data set (e.g. fashion MNIST).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copied from Lab 8\n",
    "\n",
    "try:\n",
    "    experiments\n",
    "except NameError:\n",
    "    experiments = []\n",
    "\n",
    "    \n",
    "## Helper functions\n",
    "def visualize_experiments(experiments):\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    for experiment in experiments:\n",
    "        exp_name, _, info = experiment\n",
    " \n",
    "        ax = plt.subplot(2, 1, 1)\n",
    "        ax.set_title('Validation Accuracy')\n",
    "        plt.plot(info.history['val_accuracy'], label=exp_name)\n",
    "        plt.legend()\n",
    "\n",
    "        ax = plt.subplot(2, 1, 2)\n",
    "        ax.set_title('Validation Loss')\n",
    "        plt.plot(info.history['val_loss'], label=exp_name)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_info(experiment):\n",
    "    name, _, info = experiment\n",
    "    print('Params:')\n",
    "    for key in info.params:\n",
    "        print('{:20}'.format(key), info.params[key])\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    ax.set_title('Accuracy: '+ name)\n",
    "    plt.plot(info.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.plot(info.history['accuracy'], label='train_accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    ax.set_title('Loss: ' + name)\n",
    "    plt.plot(info.history['val_loss'], label='val_loss')\n",
    "    plt.plot(info.history['loss'], label='loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def keep_best(experiments, n):\n",
    "    \"\"\" Return the n best experiments.\"\"\"\n",
    "    if len(experiments) < n:\n",
    "        return experiments\n",
    "    \n",
    "    exp_sorted = sorted(experiments, key=lambda x: np.max(x[2].history['val_accuracy']), reverse=True)\n",
    "    return exp_sorted[:n]\n",
    "\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train(model, loss, optimizer, num_epochs, exp_name=None, use_tensorboard=False):    \n",
    "    exp_name = exp_name or 'log_{:.0f}'.format(time.time()*100)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    batch_size = 256\n",
    "\n",
    "    if use_tensorboard:\n",
    "        tensorboard = TensorBoard(log_dir='logdir/'+exp_name)\n",
    "        fit_info = model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.1, callbacks=[tensorboard])\n",
    "    else:\n",
    "        fit_info = model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.1)\n",
    "    return exp_name, model, fit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_function = None\n",
    "optimizer = None\n",
    "\n",
    "## EXPERIMENT WITH THE HYPER-PARAMETERS\n",
    "\n",
    "loss_function = tf.keras.backend.categorical_crossentropy\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "num_epochs = 25\n",
    "print('\\nBegin Training')\n",
    "exp_name = 'conv_network'\n",
    "experimentConv = train(conv_model, loss_function, optimizer, num_epochs, exp_name=exp_name)\n",
    "experiments.append(experimentConv)\n",
    "\n",
    "exp_name = 'dense_network'\n",
    "experimentDense = train(dense_model, loss_function, optimizer, num_epochs, exp_name=exp_name)\n",
    "experiments.append(experimentDense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_info(experimentConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_info(experimentDense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA STUFF FOR FINAL ASSIGNMENT ;)\n",
    "*This section is optional for the lab, but if you end up working on a deep learning project for your final assignment, I highly suggest to take a look at the following articles. They were very useful to improve the quality of my fruit classifier.* - Francesco\n",
    "\n",
    "## Image Data Augmentation\n",
    "[By Jason Brownlee]\n",
    "\n",
    "The performance of deep learning neural networks often improves with the amount of data available.\n",
    "\n",
    "Data augmentation is a technique to artificially create new training data from existing training data. This is done by applying domain-specific techniques to examples from the training data that create new and different training examples.\n",
    "\n",
    "Image data augmentation is perhaps the most well-known type of data augmentation and involves creating transformed versions of images in the training dataset that belong to the same class as the original image.\n",
    "\n",
    "Transforms include a range of operations from the field of image manipulation, such as shifts, flips, zooms, and much more.\n",
    "\n",
    "The intent is to expand the training dataset with new, plausible examples.\n",
    "\n",
    "For more information:\n",
    "https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "## Use Early Stopping to Halt the Training of Neural Networks At the Right Time\n",
    "[By Jason Brownlee]\n",
    "\n",
    "A problem with training neural networks is in the choice of the number of training epochs to use.\n",
    "\n",
    "Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset.\n",
    "\n",
    "In [this tutorial](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/), you will discover the Keras API for adding early stopping to overfit deep learning neural network models.\n",
    "\n",
    "## Dropout Regularization in Deep Learning Models With Keras\n",
    "[By Jason Brownlee]\n",
    "\n",
    "A simple and powerful regularization technique for neural networks and deep learning models is dropout.\n",
    "\n",
    "In [this post](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) you will discover the dropout regularization technique and how to apply it to your models in Python with Keras.\n",
    "\n",
    "After reading this post you will know:\n",
    "\n",
    "How the dropout regularization technique works.\n",
    "How to use dropout on your input layers.\n",
    "How to use dropout on your hidden layers.\n",
    "How to tune the dropout level on your problem.\n",
    "\n",
    "## Transfer Learning in Keras with Computer Vision Models: Start from Pre-trained models\n",
    "[By Jason Brownlee]\n",
    "\n",
    "Deep convolutional neural network models may take days or even weeks to train on very large datasets.\n",
    "\n",
    "A way to short-cut this process is to re-use the model weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet image recognition tasks. Top performing models can be downloaded and used directly, or integrated into a new model for your own computer vision problems.\n",
    "\n",
    "In [this post](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/), you will discover how to use transfer learning when developing convolutional neural networks for computer vision applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
