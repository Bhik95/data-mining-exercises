{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7IYFVoXJSd-"
   },
   "source": [
    "(Material adapted by Luis Fernando Laris Pardo's)\n",
    "# Autoencoders\n",
    "For today's exercise we are going to be implementing autoencoders, one cool implementation can be found [here](https://medium.com/@sorenlind/a-deep-convolutional-denoising-autoencoder-for-image-classification-26c777d3b88e) where autoencoders are used to get unnoisy images from magic the gathering cards. \n",
    "\n",
    "For this I have used the most common starter example for autoencoders that can be found using the mnist dataset. Remember that the autoencoder is doing something similar to the following:\n",
    "\n",
    "![image](https://www.pyimagesearch.com/wp-content/uploads/2020/02/keras_denoising_autoencoder_overview.png)\n",
    "\n",
    "As in previous weeks the code is already given, but I would ask you to do the following things:\n",
    "\n",
    "* Add noise to the input images and see how your autoencoder works with these.\n",
    "* Add more dense layers to your autoencoder model (hint: you can use: x = Dense(128, activation='relu')(input_img) as your initial layer and then instead of the \"encoded\" variable as you have it right now you can change input_img for x)\n",
    "* create an autoencoder that uses CNNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nZJPE6FPzqz-",
    "outputId": "adc85b47-dd50-4432-d8ac-7169455f5bae"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adadelta, SGD, Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_E-CPgCMKpx"
   },
   "source": [
    "### Read the data and flatten it\n",
    "In this case, first we are going to use dense layers, here is another way to flattern your data before giving it to the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vd8A7BtSLvAB"
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ItV_5A9iz1Me",
    "outputId": "a2f464b2-7412-47b5-9db5-5070cdd62769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# flatten the data (if working with Dense Network)\n",
    "\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:]))) \n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Add Noise to x_train, x_test\n",
    "x_train_noisy = x_train # + np.random.normal(loc=0.0, scale=0.1, size=x_train.shape)\n",
    "x_test_noisy = x_test # + np.random.normal(loc=0.0, scale=0.1, size=x_test.shape)\n",
    "\n",
    "# OPTIONAL - Transform the data (random translation/rotation/scale/shear/whatever)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSKi870MMdtv"
   },
   "source": [
    "### Create your autoencoder\n",
    "We can now create the model for the autoencoder, in this case is a very simple one where of an input layer, one hiden layer (the encoded part) and an output later (the decoded part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZzzEFXw0EIx"
   },
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "saTWPiRNNB4g"
   },
   "source": [
    "### The encoder and decoder models\n",
    "This models we are going to use them later to test the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hv5B9yYa2k5-"
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQoEBrEkN0sn"
   },
   "source": [
    "### Time to train our model\n",
    "Try different optimizers, deffinitely SGD is not the best for this task. you should be able to ger good results with the setup given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlQOqHXZ2oao"
   },
   "outputs": [],
   "source": [
    "opt = Adam()\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8QXryo-v3HZP",
    "outputId": "ff88c4e3-eded-4ebc-8586-2e349ad43ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3849 - val_loss: 0.1859\n",
      "Epoch 2/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1776 - val_loss: 0.1518\n",
      "Epoch 3/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1478 - val_loss: 0.1329\n",
      "Epoch 4/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1311 - val_loss: 0.1215\n",
      "Epoch 5/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1205 - val_loss: 0.1133\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1129 - val_loss: 0.1074\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1074 - val_loss: 0.1028\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1031 - val_loss: 0.0995\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.0971\n",
      "Epoch 10/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0979 - val_loss: 0.0955\n",
      "Epoch 11/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0966 - val_loss: 0.0944\n",
      "Epoch 12/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0956 - val_loss: 0.0938\n",
      "Epoch 13/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0950 - val_loss: 0.0934\n",
      "Epoch 14/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 15/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0942 - val_loss: 0.0929\n",
      "Epoch 16/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0938 - val_loss: 0.0926\n",
      "Epoch 17/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 18/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 19/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 20/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0934 - val_loss: 0.0923\n",
      "Epoch 21/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 22/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 23/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0934 - val_loss: 0.0920\n",
      "Epoch 24/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 25/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 26/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 27/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 28/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 29/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 30/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 31/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0918\n",
      "Epoch 32/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0918\n",
      "Epoch 33/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0918\n",
      "Epoch 34/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 35/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 36/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 37/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 38/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0916\n",
      "Epoch 39/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 40/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 41/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 42/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 43/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 44/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 45/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 46/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0916\n",
      "Epoch 47/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 48/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 49/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0917\n",
      "Epoch 50/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 51/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0916\n",
      "Epoch 52/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 53/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0915\n",
      "Epoch 54/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0915\n",
      "Epoch 55/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 56/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0914\n",
      "Epoch 57/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 58/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 59/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 60/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 61/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 62/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0914\n",
      "Epoch 63/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0915\n",
      "Epoch 64/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 65/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 66/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 67/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0913\n",
      "Epoch 68/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 69/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 70/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 71/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0913\n",
      "Epoch 72/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 73/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 74/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 75/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 76/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 77/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0914\n",
      "Epoch 78/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0914\n",
      "Epoch 79/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 80/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0914\n",
      "Epoch 82/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 83/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0913\n",
      "Epoch 84/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 85/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0914\n",
      "Epoch 86/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 87/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 88/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 89/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 90/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 91/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 92/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 93/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 94/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0913\n",
      "Epoch 95/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 96/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 97/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 98/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 99/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0912\n",
      "Epoch 100/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0913\n",
      "Epoch 101/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0913\n",
      "Epoch 102/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 103/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0913\n",
      "Epoch 104/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0925 - val_loss: 0.0912\n",
      "Epoch 105/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 106/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 107/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 108/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0912\n",
      "Epoch 109/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0912\n",
      "Epoch 110/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 111/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 112/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 113/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 114/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 115/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 116/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0912\n",
      "Epoch 117/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0912\n",
      "Epoch 118/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 119/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0911\n",
      "Epoch 120/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 121/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 122/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 123/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 124/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 125/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 126/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0912\n",
      "Epoch 127/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 128/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 129/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 130/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 131/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 132/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0912\n",
      "Epoch 133/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 134/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0923 - val_loss: 0.0911\n",
      "Epoch 135/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 136/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 137/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 138/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 139/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 140/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 141/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 142/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0911\n",
      "Epoch 143/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 144/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0910\n",
      "Epoch 145/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 146/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 147/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 148/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 149/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 150/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 151/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0910\n",
      "Epoch 152/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 153/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 154/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 155/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0911\n",
      "Epoch 156/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0910\n",
      "Epoch 157/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 158/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0910\n",
      "Epoch 159/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 160/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 162/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0910\n",
      "Epoch 163/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 164/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0910\n",
      "Epoch 165/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 166/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0909\n",
      "Epoch 167/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 168/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 169/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0910\n",
      "Epoch 170/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 171/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0917 - val_loss: 0.0910\n",
      "Epoch 172/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0917 - val_loss: 0.0909\n",
      "Epoch 173/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0917 - val_loss: 0.0909\n",
      "Epoch 174/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 175/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0909\n",
      "Epoch 176/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 177/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0908\n",
      "Epoch 178/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0917 - val_loss: 0.0909\n",
      "Epoch 179/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 180/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 181/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - val_loss: 0.0909\n",
      "Epoch 182/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 183/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0909\n",
      "Epoch 184/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 185/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 186/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0920 - val_loss: 0.0909\n",
      "Epoch 187/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 188/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0910\n",
      "Epoch 189/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0908\n",
      "Epoch 190/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 191/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0917 - val_loss: 0.0909\n",
      "Epoch 192/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0916 - val_loss: 0.0909\n",
      "Epoch 193/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0909\n",
      "Epoch 194/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 195/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0908\n",
      "Epoch 196/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 197/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0908\n",
      "Epoch 198/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - val_loss: 0.0908\n",
      "Epoch 199/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 200/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0917 - val_loss: 0.0908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f38523e0a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the noisy data as your input and the non-noisy data as the ground truth\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9kwibqJOYI1"
   },
   "source": [
    "### Now let's test our Autoencoder!\n",
    "One important thing to notice is how reshape is used to rearrange the image plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtAJO86Z3MSO"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "aVHmCaYB3PjB",
    "outputId": "dcf11702-f417-497b-a3b0-a70130ade4eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAADnCAYAAACkCqtqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABB8klEQVR4nO3dedxV4/7/8es+hJLSXGjO0KRoFBk6nSJyiij6OU7oGELHEA4OIseXyFwZjkyRoUIkU+EkIVKaVSopaVKijPfvj/PwOe/r6l67fe/23ve69349//os13XvvVprX2uvvVyf61NQWFjoAAAAAAAAEC9/KOkdAAAAAAAAwPZ4aAMAAAAAABBDPLQBAAAAAACIIR7aAAAAAAAAxBAPbQAAAAAAAGKIhzYAAAAAAAAxtGtxOhcUFFAfvIQUFhYWpON1OIclal1hYWG1dLwQ57HkMBZzAmMxBzAWcwJjMQcwFnMCYzEHMBZzQpFjkZk2QPYsL+kdAOCcYywCccFYBOKBsQjEQ5FjkYc2AAAAAAAAMcRDGwAAAAAAgBjioQ0AAAAAAEAM8dAGAAAAAAAghnhoAwAAAAAAEEM8tAEAAAAAAIghHtoAAAAAAADEEA9tAAAAAAAAYmjXkt4B5KfLL7/c4rJly3ptBx98sMW9evWKfI0RI0ZY/P7773ttTzzxxM7uIgAAAAAAJYqZNgAAAAAAADHEQxsAAAAAAIAY4qENAAAAAABADLGmDbLmmWeesTjRWjXqt99+i2w799xzLe7cubPX9s4771i8YsWKZHcRJeyAAw7wthcsWGDxwIEDLb733nuztk/5bM8997R46NChFuvYc865jz/+2OJTTjnFa1u+fHmG9g4AAKBkVKpUyeI6deok9TfhPdEll1xi8Zw5cyxetGiR12/WrFmp7CJyCDNtAAAAAAAAYoiHNgAAAAAAADFEehQyRtOhnEs+JUpTYl577TWLGzRo4PXr3r27xQ0bNvTa+vbta/Ett9yS1Pui5B1yyCHetqbHrVy5Mtu7k/dq1aplcf/+/S0O0xZbtWpl8QknnOC13X///RnaO6hDDz3U4nHjxnlt9erVy9j7dunSxdueP3++xV9++WXG3hc7pt+Rzjn30ksvWXzhhRdaPHLkSK/fr7/+mtkdy0HVq1e3+Nlnn7V42rRpXr8HH3zQ4mXLlmV8v35XsWJFb/vII4+0eNKkSRb//PPPWdsnoDQ4/vjjLT7xxBO9tqOPPtriRo0aJfV6YdpT3bp1Ld59990j/26XXXZJ6vWRu5hpAwAAAAAAEEM8tAEAAAAAAIgh0qOQVq1bt7a4Z8+ekf3mzp1rcTjdcN26dRZv2bLF4t12283rN336dItbtGjhtVWpUiXJPUactGzZ0tv+/vvvLR4/fnyW9yb/VKtWzdt+7LHHSmhPUFxdu3a1ONEU63QLU3DOOussi/v06ZO1/cB/6Xff8OHDI/vdd999Fj/yyCNe29atW9O/YzlGq8Y459/TaCrSmjVrvH4llRKlFf6c86/1mt66ePHizO9YKVOhQgVvW1PumzVrZnFYxZRUs3jTZRUGDBhgsaaCO+dc2bJlLS4oKNjp9w2rpALJYqYNAAAAAABADPHQBgAAAAAAIIZ4aAMAAAAAABBDJbqmTVgCWvMIV61a5bVt27bN4tGjR1v89ddfe/3Ixy1ZWiI4zP3UnG9df2H16tVJvfZll13mbTdp0iSy7yuvvJLUa6LkaU64lqF1zrknnngi27uTdy6++GKLe/To4bW1bdu22K+npWSdc+4Pf/jf/xuYNWuWxe+++26xXxu+XXf931d4t27dSmQfwrUyLr30Uov33HNPr03XqEJm6Pjbb7/9Ivs9/fTTFuv9FaJVrVrV4meeecZrq1y5ssW6ltBFF12U+R2LcO2111pcv359r+3cc8+1mPvm7fXt29fim2++2WurXbt2kX8Trn2zfv369O8Y0kavjwMHDszoey1YsMBi/S2E9NGS63qtds5fY1XLtDvn3G+//WbxyJEjLX7vvfe8fnG4TjLTBgAAAAAAIIZ4aAMAAAAAABBDJZoeddttt3nb9erVS+rvdFrnd99957Vlc9rZypUrLQ7/LTNmzMjafsTJhAkTLNapas7552rDhg3Ffu2wfGyZMmWK/RqIn4MOOsjiMJ0inIKO9Lvzzjst1mmiqTrppJMit5cvX25x7969vX5hmg127JhjjrH4sMMOszj8PsqksPSxpq2WK1fOayM9Kv3C8u7XXHNNUn+nqaeFhYVp3adcdeihh1ocTrFXN954Yxb2ZntNmzb1tjWlfPz48V4b363b03SZu+66y+IqVap4/aLGy7333utta7p3Kve8SE6YCqOpTpriMmnSJK/fjz/+aPGmTZssDr+n9L709ddf99rmzJlj8QcffGDxzJkzvX5bt26NfH0kT5dTcM4fY3qvGX4mktWuXTuLf/nlF69t4cKFFk+dOtVr08/cTz/9lNJ7J4OZNgAAAAAAADHEQxsAAAAAAIAY4qENAAAAAABADJXomjZa4ts55w4++GCL58+f77U1btzY4kR5xe3bt7f4yy+/tDiqRF9RNI9t7dq1Fms569CKFSu87Xxd00bp+hWpGjRokMUHHHBAZD/NJS1qG/F1xRVXWBx+ZhhHmTFx4kSLtSR3qrS06ZYtW7y2unXrWqxlZz/88EOv3y677LLT+5HrwnxuLdu8ZMkSi//1r39lbZ/+/Oc/Z+29sL3mzZt7261atYrsq/c2r776asb2KVdUr17d2z755JMj+5599tkW631jpuk6Nm+++WZkv3BNm3A9SDh3+eWXW6wl3JMVrtN27LHHWhyWDdf1bzK5BkauSrTOTIsWLSzWUs+h6dOnW6y/K5ctW+b1q1OnjsW6lqlz6VkHENvT5wEDBgywOBxjFSpUKPLvv/rqK2/7P//5j8VffPGF16a/QXRtxbZt23r99JrQrVs3r23WrFkWa9nwdGOmDQAAAAAAQAzx0AYAAAAAACCGSjQ96q233kq4rcJSbb8Ly422bNnSYp3m1KZNm6T3a9u2bRYvWrTI4jBlS6dK6dR07JwTTjjBYi2dudtuu3n9vvnmG4v/8Y9/eG0//PBDhvYOO6tevXreduvWrS3W8eYcpRHT5aijjvK2DzzwQIt1em+yU33D6Z86PVlLZzrnXKdOnSxOVI74/PPPt3jEiBFJ7Ue+ufbaa71tnSKuU/HDFLV00+++8LPFdPHsSpSyEwrTCJDYHXfc4W3/v//3/yzW+0vnnHvuueeysk+hjh07WlyjRg2v7dFHH7X4ySefzNYulRqauuucc/369Suy3+zZs73tNWvWWNy5c+fI169YsaLFmnrlnHOjR4+2+Ouvv97xzua58P7/qaeesljToZzz04MTpQyqMCVKhctfIP0eeOABb1vT2hKV79bnBp999pnFV199tddPf9eHOnToYLHehz7yyCNeP32+oNcA55y7//77LR47dqzF6U6VZaYNAAAAAABADPHQBgAAAAAAIIZKND0qHTZu3OhtT5kypch+iVKvEtGpx2Eqlk7FeuaZZ1J6fWxP02XCKZFKj/k777yT0X1C+oTpFCqbVTdynaahjRkzxmtLNN1UaTUvnfI5ePBgr1+idER9jb/97W8WV6tWzet32223WbzHHnt4bffdd5/FP//88452O6f06tXL4rBiweLFiy3OZqU1TXML06Hefvtti7/99tss7VH+OvLIIyPbwqo0idITsb3CwkJvWz/rq1at8toyWQGobNmy3rZO/b/gggssDvf3rLPOytg+5QJNd3DOub322stirTYT3rPo99Npp51mcZiS0bBhQ4tr1qzptb344osWH3fccRZv2LAhmV3PC+XLl7c4XAJBl1FYt26d13b77bdbzFIJ8RHe12nVpnPOOcdrKygosFh/F4Sp80OHDrU41eUUqlSpYrFWMb3hhhu8frpMS5hamS3MtAEAAAAAAIghHtoAAAAAAADEEA9tAAAAAAAAYqjUr2mTCdWrV7d4+PDhFv/hD/4zLi1HTR5q6l544QVvu0uXLkX2e/zxx73tsPwtSofmzZtHtum6Jtg5u+76v8t7smvYhGtD9enTx+IwbzxZuqbNLbfcYvGwYcO8fuXKlbM4/By89NJLFi9ZsiSl/SitTjnlFIv1GDnnfz9lmq6R1LdvX4t//fVXr9+QIUMszrf1h7JFS5RqHApz/D/99NNM7VLeOf74471tLaeuazmFazAkS9dROfroo7229u3bF/k3zz//fErvla923313b1vXBLrzzjsj/07LB48aNcpivVY751yDBg0iX0PXWsnkekilWY8ePSy+6qqrvDYtw61l751zbtOmTRndL6QmvI4NGjTIYl3DxjnnvvrqK4t1bdkPP/wwpffWtWpq167ttelvy4kTJ1ocrmOrwv194oknLM7kWn7MtAEAAAAAAIghHtoAAAAAAADEEOlRRRgwYIDFWpY2LC++cOHCrO1TrqlVq5bF4fRunbKqKRk67d4557Zs2ZKhvUO66XTufv36eW0zZ860+I033sjaPuG/tFR0WCI21ZSoKJrmpCk2zjnXpk2btL5XaVWxYkVvOyoVwrnUUy9SoeXaNd1u/vz5Xr8pU6ZkbZ/yVbJjJZufj1x09913e9vHHHOMxfvss4/XpqXXder8iSeemNJ762uEpbzV0qVLLQ5LTiMxLdcd0vS3MIU/SuvWrZN+7+nTp1vMvWzREqV+6n3jypUrs7E72EmaouTc9qnV6pdffrG4Xbt2Fvfq1cvrd9BBBxX591u3bvW2GzduXGTsnH+fW6NGjch9UmvWrPG2s5UWzkwbAAAAAACAGOKhDQAAAAAAQAyRHuWcO/zww73tcJXy3+lK5s45N2fOnEztUs4bO3asxVWqVIns9+STT1qcb1Vjcknnzp0trly5stc2adIki7UqA9InrHyndOpppumU/3CfEu3jDTfcYPEZZ5yR9v2Kk7Ciyb777mvx008/ne3dMQ0bNizyv/M9mH2J0jDSUbkI//Xxxx972wcffLDFLVu29NqOPfZYi7Uqytq1a71+jz32WFLvrdVIZs2aFdlv2rRpFnOPVDzh9VRT2TQFMUzB0AqYPXv2tDisNqNjMWzr37+/xXqu582bl8yu54UwFUbpeLv++uu9thdffNFiKubFx+TJk71tTaXW3wjOOVenTh2L77nnHosTpYpqulWYipVIVErUb7/95m2PHz/e4osvvthrW716ddLvtzOYaQMAAAAAABBDPLQBAAAAAACIIR7aAAAAAAAAxBBr2jjnunXr5m2XKVPG4rfeesvi999/P2v7lIs0X/jQQw+N7Pf2229bHOaqonRq0aKFxWFO6vPPP5/t3ckL5513nsVhbm5J6d69u8WHHHKI16b7GO6vrmmT67777jtvW3PydU0N5/z1oTZs2JDW/ahevbq3HbW+wNSpU9P6vijaEUccYfHpp58e2W/Tpk0WUwo3vTZu3GhxWNpet6+88sqdfq8GDRpYrGuBOedfEy6//PKdfq989eabb3rbOnZ03ZpwnZmodTXC1xswYIDFL7/8ste2//77W6zrY+j3dr6rVq2axeE9ga79dt1113lt1157rcUjR460WMusO+evm7J48WKL586dG7lPTZs29bb1dyHX28TCMty6HtTee+/ttenasrru7Pr1671+K1assFg/E/qbwznn2rZtW+z9ffDBB73tq6++2mJdryqbmGkDAAAAAAAQQzy0AQAAAAAAiKG8TY8qW7asxVo6zjnnfvrpJ4s1Pefnn3/O/I7lkLCUt04t0xS0kE793bJlS9r3C9lRs2ZNizt27GjxwoULvX5aRg/po6lI2aRTmp1zrkmTJhbrNSCRsExuPl17wynEWsb35JNP9tpeeeUVi4cNG1bs92rWrJm3rSkZ9erV89qiUgLiknqX6/T79A9/iP7/bW+88UY2dgcZpikf4djT9KvwWonkhSmlp556qsWatl2xYsXI17j33nstDtPitm3bZvG4ceO8Nk3/6Nq1q8UNGzb0+uVzGffbb7/d4ksvvTTpv9Pr4wUXXFBknC46/nRphz59+qT9vXJZmG6k4yMVjz/+uLedKD1KU9L1c/boo496/bSkeElhpg0AAAAAAEAM8dAGAAAAAAAghnhoAwAAAAAAEEN5u6bNoEGDLA5Lz06aNMniadOmZW2fcs1ll13mbbdp06bIfi+88IK3TZnv3PDXv/7VYi0f/Oqrr5bA3iBbrrnmGm9by54msmzZMovPPPNMr03LOuYbvR6GpX+PP/54i59++uliv/a6deu8bV07o2rVqkm9Rpj3jcyIKrkergXwwAMPZGFvkG6nnHKKt/2Xv/zFYl1zwbnty94iPbRkt463008/3eunY07XHtI1bEI33XSTt924cWOLTzzxxCJfz7ntvwvzia5r8swzz3htTz31lMW77ur/lK1du7bFidb/Sgddw08/M1p23DnnhgwZktH9gHNXXHGFxcVZU+i8886zOJX7qGxipg0AAAAAAEAM8dAGAAAAAAAghvImPUqnkTvn3D//+U+LN2/e7LXdeOONWdmnXJdsib4LL7zQ26bMd26oW7dukf9948aNWd4TZNrEiRMtPvDAA1N6jXnz5lk8derUnd6nXLFgwQKLtSStc861bNnS4kaNGhX7tbWsbeixxx7ztvv27Vtkv7BEOdJjv/3287bDFI3frVy50tueMWNGxvYJmXPcccdFtr388sve9ieffJLp3cl7miqlcarC66Sm+2h61DHHHOP1q1y5ssVhifJcpyWWw+vaAQccEPl3f/zjHy0uU6aMxTfccIPXL2rJhlRp+nKrVq3S+too2jnnnGOxpqSFKXNq7ty53va4cePSv2MZwkwbAAAAAACAGOKhDQAAAAAAQAzldHpUlSpVLL7nnnu8tl122cVindrvnHPTp0/P7I7Bo9M/nXPu559/LvZrbNq0KfI1dHpkxYoVI19j77339raTTe/SKZxXXnml1/bDDz8k9Rq56IQTTijyv0+YMCHLe5KfdKpuogoKiablP/jggxbvs88+kf309X/77bdkd9HTvXv3lP4un3366adFxumwdOnSpPo1a9bM254zZ05a9yNfdejQwduOGsNh9UWUTuF1+Pvvv7f4jjvuyPbuIMOeffZZizU9qnfv3l4/XT6ApRuS89ZbbxX53zWd2Dk/PeqXX36xeNSoUV6/hx56yOK///3vXltU2ioyo23btt62XhvLly8f+Xe67IZWi3LOuR9//DFNe5d5zLQBAAAAAACIIR7aAAAAAAAAxBAPbQAAAAAAAGIo59a00bVqJk2aZHH9+vW9fkuWLLFYy38j+2bPnr3Tr/Hcc89526tXr7a4Ro0aFof5wun29ddfe9s333xzRt8vTo444ghvu2bNmiW0J3DOuREjRlh82223RfbTcrKJ1qNJdq2aZPuNHDkyqX4oGbomUlHbv2MNm8zQNflC69ats/juu+/Oxu4gA3RtBb1Pcc65b775xmJKfOce/Z7U7+c///nPXr/rr7/e4jFjxnhtixYtytDe5abXX3/d29b7cy0R3b9/f69fo0aNLD766KOTeq+VK1emsIfYkXDtw7322qvIfrommHP+ulHvvfde+ncsS5hpAwAAAAAAEEM8tAEAAAAAAIihnEuPatiwocWtWrWK7KflnDVVCukTllIPp32m0ymnnJLS32mZv0RpHS+99JLFM2bMiOz3n//8J6X9yAU9e/b0tjVVcebMmRa/++67WdunfDZu3DiLBw0a5LVVq1YtY++7du1ab3v+/PkW/+1vf7NYUxgRP4WFhQm3kVldu3aNbFuxYoXFmzZtysbuIAM0PSocX6+88krk32lKQKVKlSzWzwVKj08//dTi6667zmsbOnSoxf/617+8tjPOOMPirVu3Zmbncojeizjnl10/9dRTI//umGOOiWz79ddfLdYxe9VVV6WyiyiCXu+uuOKKpP5m9OjR3vbbb7+dzl0qMcy0AQAAAAAAiCEe2gAAAAAAAMQQD20AAAAAAABiqNSvaVO3bl1vOyzp9rtwTQctc4vMOOmkk7xtzUUsU6ZMUq/RtGlTi4tTrvuRRx6xeNmyZZH9xo4da/GCBQuSfn38V7ly5Szu1q1bZL/nn3/eYs0BRuYsX77c4j59+nhtPXr0sHjgwIFpfd+wzP3999+f1tdHduyxxx6RbayfkBn6vajr84W2bdtm8c8//5zRfULJ0O/Jvn37em2XXHKJxXPnzrX4zDPPzPyOIaMef/xxb/vcc8+1OLynvvHGGy2ePXt2ZncsB4TfW3//+98tLl++vMWtW7f2+lWvXt3i8PfEE088YfENN9yw8zsJ55x/PubNm2dxot+OOgb03OYSZtoAAAAAAADEEA9tAAAAAAAAYqjUp0dpCVnnnKtTp06R/d555x1vm/Kl2Xfbbbft1N+ffvrpadoTpItOzd+4caPXpmXS77777qztE7YXllnXbU0pDa+n3bt3t1jP54MPPuj1KygosFinsqL06tevn7f97bffWnzTTTdleW/yw2+//WbxjBkzvLZmzZpZvHjx4qztE0rGOeecY/HZZ5/ttf373/+2mLGYW9auXettd+7c2eIwNefKK6+0OEyhw46tWbPGYr3X0VLqzjnXvn17iwcPHuy1ffPNNxnau/zWqVMni/fbbz+LE/1217RRTSHOJcy0AQAAAAAAiCEe2gAAAAAAAMRQQXHShAoKCmKRU3TEEUdYPHHiRK9NV5xWbdu29bbDqcdxV1hYWLDjXjsWl3OYpz4uLCxsveNuO8Z5LDmMxZzAWNyBCRMmeNvDhg2zeMqUKdnenSLl8ljcZ599vO0hQ4ZY/PHHH1ucA9XZ8nYs6r2sVgJyzk9hHTFihNemqcg//fRThvaueHJ5LMZFWB33sMMOs7hdu3YW70SKct6OxVySC2Nx1qxZFjdv3jyy39ChQy3WdMEcUORYZKYNAAAAAABADPHQBgAAAAAAIIZ4aAMAAAAAABBDpbLkd8eOHS2OWsPGOeeWLFli8ZYtWzK6TwAA5AotgYrsW7Vqlbd91llnldCeIFOmTp1qsZa4BYrSq1cvb1vX/WjUqJHFO7GmDRALlStXtrig4H9L9IQl1u+6665s7VIsMNMGAAAAAAAghnhoAwAAAAAAEEOlMj0qEZ0u+Mc//tHiDRs2lMTuAAAAAEDKNm/e7G3Xr1+/hPYEyKxhw4YVGd90001ev9WrV2dtn+KAmTYAAAAAAAAxxEMbAAAAAACAGOKhDQAAAAAAQAwVFBYWJt+5oCD5zkirwsLCgh332jHOYYn6uLCwsHU6XojzWHIYizmBsZgDGIs5gbGYAxiLOYGxmAMYizmhyLHITBsAAAAAAIAY4qENAAAAAABADBW35Pc659zyTOwIEqqbxtfiHJYczmPpxznMDZzH0o9zmBs4j6Uf5zA3cB5LP85hbijyPBZrTRsAAAAAAABkB+lRAAAAAAAAMcRDGwAAAAAAgBjioQ0AAAAAAEAM8dAGAAAAAAAghnhoAwAAAAAAEEM8tAEAAAAAAIghHtoAAAAAAADEEA9tAAAAAAAAYoiHNgAAAAAAADHEQxsAAAAAAIAY4qENAAAAAABADPHQBgAAAAAAIIZ4aAMAAAAAABBDPLQBAAAAAACIIR7aAAAAAAAAxBAPbQAAAAAAAGKIhzYAAAAAAAAxxEMbAAAAAACAGOKhDQAAAAAAQAzx0AYAAAAAACCGeGgDAAAAAAAQQzy0AQAAAAAAiKFdi9O5oKCgMFM7gsQKCwsL0vE6nMMSta6wsLBaOl6I81hyGIs5gbGYAxiLOYGxmAMYizmBsZgDGIs5ocixyEwbIHuWl/QOAHDOMRaBuGAsAvHAWATiocixyEMbAAAAAACAGOKhDQAAAAAAQAzx0AYAAAAAACCGeGgDAAAAAAAQQzy0AQAAAAAAiCEe2gAAAAAAAMQQD20AAAAAAABiaNeS3gHkj913393ik046yeI77rjD61exYkWLN2zYYPHo0aO9fk8++aTFK1eu9NrKlClj8R577GHxmjVrvH4//fRTUvuOklFQUGBxYWFhkf89bENm/OEP0c/49fhzLgAA2HlR90CIHz1X4f3Sr7/+mu3dQQ5ipg0AAAAAAEAM8dAGAAAAAAAghnhoAwAAAAAAEEMFxcmRLCgoIKGyhBQWFhbsuNeOZfoc6loyBxxwgNc2ZMgQi4866iiLdQ0b56LXzghzQrds2WLxu+++67UNHjzY4tmzZ1v8888/R+57FnxcWFjYOh0vVNrGYqJcXz3/Bx10kNdWt25dixcuXFhk7JxzP/zwg8WZzvsuLWMxFTp+nXOuYcOGFp966qkW16tXz+v3ySefWDxmzBivbf369RbHKCc/J8aijiWNwzWf1G+//VZk7Fyszk9Scnkspko/B7qOnHPOlStXzuKtW7cWGTuX9c9BToxFHXO77LKLxeGx1DFX2sZbIozF9Aiv3bvttpvF+rlyzr8n1vUZd+JzVSrHYkmucbjnnntavP/++1tcrVo1r99XX31l8fLly702PXe//PKLxan+OxiLOaHIschMGwAAAAAAgBjioQ0AAAAAAEAMUfIbaaXltbt06eK1abqUTvPctm2b109TmDQOp/LrlMJweremZOh0w0ygJOOOJTouZcuWtbhDhw5eW/369S3WdLjPP/88jXuX3/TzW6FCBa+tZ8+eFvft29ficOpvu3btLF65cqXX9vLLL1uc6bGY63bd1f/K3nvvvS2uXLmyxXodds4fO2vWrLG4OGkxUSmO4T6p8HyH1/Bk3heJhakBmgLVp08fr61jx44WT5gwweKJEyd6/TTdFP+jx3qvvfby2ho0aGCx3t/ovYhzzq1bt85ivfcJ079TGRPhZ0HT48I0dO2r14fw3EeN2XwSHteo9NPwnKXjuqbvpak4zvnXXv0sbdq0yeuXi+cwKjXYueh78kTpwPo3eg11zrn27dtbPHDgQK/tsMMOs1jvZcN90t8rmzdv9trmzZtn8bBhwyx+5513vH7hbyXkH2baAAAAAAAAxBAPbQAAAAAAAGIoVulROqU0rGKi0850ynU4XSwdK28jeeFq9jpFWGPn/GnCmjIxevRor9+XX35psU5ZbN3aX0hbpymG6Rr77befxStWrLA4HZ+J8LOpq/v/+OOPXhvpINsLz4FO8a1evbrXplPGdcX9Eq52klN0Gq9WP3DOufPOO8/iWrVqWRyOe70+X3DBBV7b+++/b/E333xjMecsOXoN1GuNc841adLE4hYtWlj83Xffef3mzJlj8erVqy1O9RzoNVDTspzz00Y2bNjgtel+JUp9zeXPRqJUC/13J3sMwtfTz8H111/vtWk6ncavv/56Uu+Vb8Jjqyne1157rdemY3Hu3LkW//vf//b6bdy4scjXD6+pqaR1hGmRbdu2tbhNmzZe2/fff2/xlClTLF66dKnXT8dpLo9L56LPR5guU6dOnSL/Xu81nfPTzpJNUQqPsR7/8P5Sz7d+N4RV4/R3Uq6cQz2eia6pidKo9LvrtNNOs/iqq67y+lWpUiXyNVSiY6vnJExz0/3Q78+LLrrI6/fZZ59ZrOlWKJ6STHfcWcy0AQAAAAAAiCEe2gAAAAAAAMQQD20AAAAAAABiKCtr2kTl5NeuXdvr17hxY4u1xJpzzlWqVMnir7/+2mLNHXbOLwWsZdWKk4umuZK6pkaYk6rraoRrbOhaJrlWbk/PZ7iWjJ7DMEd7xIgRFr/wwgsWh8cu6r3C0pnNmjWzWPPznXPu4osvtnjmzJkWax53quKY55hNyeZ/JktLkYafp0WLFln8xRdfWMxaQelTt25di5944gmvTdeGSpTLrWuchGtP3XbbbRZfc801Fq9atcrrl2vXyXTR8RZ+Z/bo0cPigw46yOJp06Z5/SZPnmyx5sKn49pVr149b/vggw+2ePHixV7brFmzLNaytLl+7vUcJrumTbLCcdm3b1+LdR2qsK+u06HrZuB/qlat6m0PHjzY4i5dunhtegw/+OADixcuXOj103Wd9HynulaGCr8/e/fubbFe553zrwk6FtNRery00ntWvb+87rrrvH66PpCuWzNmzBiv38MPP2yxriXmXPLXPO0XruEZtZ5Ros9SPtB1EvW46No0zvnfn5dddpnF4bjX4xmOD/39outVhevP6T1SonWL9POkawA6l7/3vVFrFDnnr6dYs2ZNizt16uT1O/300y0+8MADvTY9rvp78fnnn/f66X3V2rVrvTb9bZnJ85TfIxsAAAAAACCmeGgDAAAAAAAQQymnR4VTfKNKEDrnTznUNJZwWvUJJ5xgcTh9Scul6dSjQw45xOun08x0anA4rVyFKTM6VVTLr4VT2nQalab+OOdPA8+1cntRUw+d88/9pEmTvDYtKxpO84yiU+Huuecer01TN8KppjplLkzT2lnh1Ldcn7IYlQ6VqrBkeqtWrSwOx+mLL75o8Q8//JDW/chnOnX33nvvtbh+/fpev6hp1omuY+E14aijjrJ41KhRFj/++ONeP02Z1CnCO3q/XKfjRafsO+dcy5YtLdbrsn43OefcmjVrLE5HKpJ+LmrUqOG1NWrUyOJwCrGmZuVTKWGV7utpWD62c+fOFoffffpd9dxzz1mc7PdxPtDzs++++3ptTZs2jfw7TeW96667LNax51z0Zz3Vcan7G943a/n3cCy+//77RbaF6R+5LByLek/5zDPPWKzXtPDv9PdDmDKnqTP6/eacc0uWLLE40THXz0t4r6nfk1Fpd0Vt55owFUl/Z+p3VVgyffbs2RYvWLDAYk3Zd86/Po4ePdpru+OOOyzW3476feycn46qvyud83+rzpkzx+IwPSqX04gTPTfQkuh6P+mcn+Kmqdnh8wV9hhDe1+q9yGGHHWaxLvfhnH+d/PDDD702fQagy7Sk+5wx0wYAAAAAACCGeGgDAAAAAAAQQzy0AQAAAAAAiKGU17RJtYS25gZ+++23Xr9ly5ZZHOZiaz6a/l24zoXmsWn5rzDvW18jLEuqZduOOeYYi8MycFo+7u233/baPv30U4tzLZ9U8/+0/Lpz/nEI16VIJW/+2GOPtbhdu3Zem+YlhuXAL7nkEos11xfFl+waDIk+5/oamp/qnHO9evWyOCzdrteEdOT8a5zL+cGh8ByeffbZFv/pT3+yONH6T3p+wxLBulZJmJ+v60sdeuihFjdp0sTrd/jhh1t8xRVXeG2J8vVzXfny5S0+/vjjvTZdg0hz8ufOnev1i1p3K8ztTvbY6j4deeSRXpuuS/XSSy95bbrGQ76dx2QkW/5b+4XrrIRlvtWGDRssHjt2bFLvlei9Va6cTx0TYQltXV8qHFOffPKJxfq9lexxSbROZCJ6H3rppZd6bbr/ukaLc8599tlnFufTOjZKf1c459zw4cMt3n///S0Oz40eLy3lvXLlSq9f3759LT7llFO8Nr1H1fWFEp2LfLpn2RG9VwmveXqcdE2pcE0b/f3y1VdfWdy9e3ev35QpUywO14vTe59khZ+nefPmWazjPleuqVH0OIS/0Tt27GjxhRdeaHG47qKuZ6SvFz5f0Gt3+JtQ1zaqUKGCxeE9qq4R1qBBA69N17a68cYbLQ4/czuLmTYAAAAAAAAxxEMbAAAAAACAGEo5PSqRROXmNJ1p6dKlXj+dvhlOA9Rp1TodLSz1piUatfxh+HofffSRxevWrfPaNA1Kp9116NDB66cl3cLUn3yZbhr+u7UkWqpTOXUa2y233BLZT6e/haUWtZxirk8xzLTw+On0cW1LNL1b/0ZTZJxzrnnz5haHUxq15GGq08yj9jefhNOHb775ZovDEuxKr2N6vQ5TSjUFKjzGeu3WktWVKlXy+mnqz7Rp07y2p556yuKoVJ9cEaYsaVnvVq1aRf7dW2+9ZXFY3jdqnCYas+F51Onouk9aYto5f+qxpuM4l/vnLkqi4xqVbpQoLVXvPU477TSvLdFYfP311y0Or7XJyvX0KP33aQlo5/yyveFxSKVstr5GovLs4Xvpfmip2TCFXK/T48eP99p0On+unLviCtMfNCVDj3l43Zo8ebLFgwcPtrhTp05eP03vD1Oxzj33XIs1tS5c8gH/FY4BTV/T+wrnnHvnnXcs1t8o4edcf6Pob4bHHnvM66e/EcPU8FTkW0n234XnUO8BBw4c6LX179/fYi2RHn5vvfDCCxaPGTPGYr3vdM5/bhD+5tfPSNeuXS2+//77vX577LGHxeGzhzBNOVOYaQMAAAAAABBDPLQBAAAAAACIoYykRyWi0ww3b97stel2OL00avpYOJVcp2NrBY1weqO+fjhlK9kKM5q6oelWRb1fvkjHv1unrOr0OZ3O65y/QvecOXO8tnyZblgSosZEomn/moITplPo1EddRd+51Cp/JUoryKfPhV4bdQq3c85VrFixyL8Jx+/TTz9t8dVXX22xpmc456eUhm36XloF4Oijj/b6aeWwfv36eW3PPfdc5D7mmnAafdu2bS0Ov+/mz59vsR6jMG016nNfnGnamnZzwQUXWFynTh2v3wcffGBxWE2F6ifpmRqv18wwJUPTbMKp/Dp9PNlzker9Ua4L00r1vkXPT/gdpmNYx1Q4tjVNJqxipekbWnUvHPf//Oc/LdbqOM7l77nT4xymkymtfqopaM45N2TIEIv1OJ555pleP01jC+n3ZL4sp7AzdOkL55y74YYbLF64cKHX9uqrr1qcbBU+PY9hWm86UqLylR7jcDz07NnT4gEDBnhtej+oxz9MndfPQaopvzoWNfU7vE8Or9FqxYoVFmdyPDPTBgAAAAAAIIZ4aAMAAAAAABBDPLQBAAAAAACIoayvaaP5hcmuW5NImJebbO5+Ipo7qXnK4f5qqTHNZyvu++U7zet2zrmTTz7ZYj2/X3zxhdfvtddeK7If0isdn+Xy5ctbrDmjzvlrlEyYMMFrC3P0o2jebJh3mqjcbi7TdRB69Ojhtenx0nzh4cOHe/0uv/xyixOtA6brJYTHWMskHnbYYRYfeeSRkf3CdVL03xJea3ON5nI759yBBx5ocbgO3KhRoyzWc5COnOrwHGtZ1Q4dOkT+3cSJEy1OZU2qXJfqNUivaw0aNLC4du3akX+zZs0ab3vGjBnF3o9Eefy5SI/L+vXrvTb9rgpLdOvaUxdddJHF4X2LrtOntDy3c35J2VtvvdVr03LHur+6lodzzr311lsWc4/0X7p+RXitXbp0qcVaIn3o0KFeP70v0fEXfs/qZ0RLDjvnn+98ui8pDj1+4Rjo0qWLxeHxS3YNGv07/RvOR2ZUrlzZ2z7jjDMsDteP0fsPXc80XF9K74n0b8K1FfWchvc2eu0+//zzI19DheNZ17XN5LU2v76NAQAAAAAASgke2gAAAAAAAMRQ1tOjVCamoKXymuE013POOcdiLd24du1ar9/o0aMtpiTcjuk0a02FOPvss71+WgZOp769/vrrXr9ly5ZZHJ53fS+N05GSh+ToFMQaNWpYXKtWLa+fnsdXXnnFa0u2vHOiMt/5Oi1cU1j0Ouac/7nXstHXXHON1y/q+IfjJtEx1qmt77zzjsUDBw70+kWViHfOuX322cfiL7/8MnI/Siv9t4fpE3ruVq9e7bXNnDnT4nSXmQzTYnr37m2xXr/D8qiTJk2yOF/HXibo+ejYsaPFYXqxfg40hdu57dN9oiS6nuZ6uql+ZmfPnu216bUynM6v41bvIcMp9ppao6/fvHlzr5+mETds2NBr08+CpiBed911Xr9kvz/ziR67cDy88cYbFo8ZM8bi8DjquR82bJjFVatWjXxfLeHunF9SXFPhwvfK52to3bp1LT722GO9tgoVKljcokULr03vH8I0liipXsv0WpmL18Odpccn/K6qXr26xYnScLdu3WpxeK51vLRv397iNm3aeP303mnPPff02vQ3Z3ivrPS7derUqV7blClTLM7k54CZNgAAAAAAADHEQxsAAAAAAIAYKtH0qFQlqhSjUwkTTVHS16hXr57X1rlzZ4s17UlXk3fOueXLlyf1XvkqnGKtaTEjR460+KijjvL66XTGN9980+J7773X6xdON1X6udD0t3SnECCaHnedthhOkdQKF2G1k0xWlMs14bXwiCOOsDg8BjrGtGKUTkPNBB2zYUqpXi80/ca53J/mr+euXLlyXpsel2+//dZrS/dnW98rrKyinye9jr777rtev0SVxJC63Xff3eLjjz/e4nDc6xh77LHHvLZUxlF4DvPpnH799dfetqbCnH766V7bQQcdZLF+x4X3QVHpwGEa1SGHHBL5Gjr+NB1x0aJF2/8jEClMN9XKsXpfqpWKnPPHn6Yhh/cemgoXpmJpJUVte+mll7x+uixDPow9/az369fPYk2Hcs6/7ul5c865Ro0aWfzZZ59ZnOj4JaouFLV/zvn3uXp9zYdzVVxhNdiVK1daHFZBjFrWQitOOefchRdeaHHNmjUtDn9nJFsFUc9b+Btz8uTJFl9wwQVe26pVq4p8jXRjpg0AAAAAAEAM8dAGAAAAAAAghnhoAwAAAAAAEEOlZk0bzUfT3O5E+dwqzEPUNRPOPPNMr01z+efNm2fxgw8+6PX78ccfd7DX+S3M0X7ooYcs7tq1q8XhOdQSsrfffrvFmv+4I5pbrOt3kGeaOeF51LKYJ554osU6fp1zbvr06RYnW54xkXw9x5pb7Zx/zQuPq14ntQx3Jo6d7peuExCWXUxUOjNcyyXX6L89XHdk48aNFofr3ei6F9pPy6yHr6njVEvNOuefKx2zzjlXv359izXHfNq0aV6/MG8dqQnHs669p2VPw3sb/Z5Mxxon+bamjf77wns8Xb/po48+8tqi1rEJvxc3bdpksa7rVb58+cjX07HnnH+PdO2111qc62t/pYPeG4bHS9fe02trWN5dPyN6LvRexjl//SIt4e6cc4cffrjFur6Nvq9zzl111VUWa3n3XKXfSUceeaTF4ThKVEr6rrvusviee+6xOLym6nmtXLmyxeF32GuvvWZxuG6RvuaKFSsszvT6gKWFHq9wjTBdF+aEE07w2vbZZx+Ldb2YcP0iHVeJSognWqdI91HX5NM1lZzzy3yX1O9/ZtoAAAAAAADEEA9tAAAAAAAAYii26VGJyqrptKdw2n/U1N1wWpyW6evWrZvXplMQNSVKS3w7t/00Ofj2339/b7tjx44W6zkMS/9effXVFn/yyScWF2dadiancIefzVyYLp5o6mCif5/+XTjGtOxi06ZNLQ5TGLUkY7JjKtE5yIXzkYoyZcp421qCNpwqumXLFoujUkpDeswTfV7C/dApzpdddpnF4ZRmpSkEzvnTlXPx/Oq/ad26dV7b559/brFeQ51zrm/fvhbrFPs1a9Z4/XSqtk4/12nHzvnfp2Ha8F577WWxno9wyjMpGum5nobpxZquptP6w2umpjumMrZDuTjekhX+2/VeJbxv2bx58069l16TnfPH2Jdffum1PfzwwxbrfWmyn61QPp1jPQ5heqiWHdYS0+Gx01Lhep2cPXu2169GjRoW33333V5bkyZNLNaxfvTRR3v9dLmGfEiPClPRfhd+r+gxCz+/Bx98sMXDhw+3WI+lc9un6v8uHNsXX3yxxeH3nY77p556yuKxY8d6/Ugb3v73+pIlSyy+7777vLaodPlwLGpa6V//+leLr7nmGq9flSpVinw95/yUqE6dOhW5f0X9XUlgpg0AAAAAAEAM8dAGAAAAAAAghnhoAwAAAAAAEEOxXdMmzB3TfEaNk80xq1Wrlrc9aNAgi7VMmHPOTZ482WIt9RbmOWJ7unbGySef7LVp/qiew6efftrrp/naJblukObM6r6HZXe1HHGYdxuHHMhUpLLfYa6prmOj+eGLFy/2+mmZxGRz8nNxXaGdFa6BocLPpeZXJ7sGSaL1NnRtgD/96U9e24gRIyyuVq1aka/nnF9GWksrOufc2rVrk9rH0kqvc1pC1jnnJkyYYHGYT9+2bVuLdT2GAw44wOun50tLg4fvpfsRltbUtYq0X0mVvixNUrk+hestaElUPZ9hadlRo0ZZrGMqlGiNE2SHnoM6dep4bSeddJLF4TpX48ePt1jXiSjOmjZ6r6afk1z7Lk10r6Dr6TnnH9c2bdpYrGsrOufcrbfearGuv5ZoTE2aNMnb1jLuuo7L0qVLvX563Q3XDUw0vqOE6/iE64yUNP2d9d5771msJbmd89eSCY+ZfndpCfXwmhp1vsLjrO+tpaid88+PrpUarj/08ssvW8x6qP+lYzHVtfD099e4ceMs7t+/v9dPx1j4nTlgwACL9bMUx2shM20AAAAAAABiiIc2AAAAAAAAMRTb9KhQKtOUdAqxTn9yzrkWLVpYHE69v//++y3WqVfYsUqVKlncuXNnr03PoU4pveWWW7x+UVMHE03vDelrJPrs6DRI3Xfn/BK6jRs3tjgsv6kleWfNmuW1lZaUulSnAerfhedDUzd0Su7HH3/s9QtLnUbR8x++V7LnO5/oMQqPl54P/dyH6TdR5zccKzqV//rrr/faNP00qoyjc37p2sGDB3ttuZ6Co8ciLA2q6YR6jJxz7tVXX7VYU8/CdGAti6mvEZa01PMa7oeeO71u7rHHHg6+dFxP99xzT69N0ymUppc659yCBQuKvR+km5aMsmXLWnzzzTd7bc2bN7f48ccf99q++eYbi5M9V+F9VVS6ca6fez0OWurXOeduvPHGIvslSnuPui46519DH330Ua9t2rRpFmtaTZiyqtfX8Fqrr5/sPVDc0qFCej+ox+zFF1/0+q1cudJi/T3hnJ8Kc+edd1rco0cPr19U2fDwnlRToHTMOueff33ffv36ef10qY1cv5/JJj03Z511lsU1a9b0+unnXlPOnXPu7bfftjjuqWvMtAEAAAAAAIghHtoAAAAAAADEUKlJj0rFoYceanHfvn29Nl1FfOLEiV7b7NmzLY77VKmSFk6r1mOu03ud86eO6pS2o446yuu3Zs0ai/X4h9Pd6tWrZ7FWRHHOudWrV1usKUphpbCuXbta3L17d68tfL/fhdWP1q9fb/H//d//eW1z584t8jVyUaJjq+f+o48+8vqlumo8fOGUWx0DYXqUps/oZ3bIkCFev1WrVlncunVriy+66CKvn1baCNM6oqbeL1u2zOunn5cw5SOfhN85Oq03nNr+ww8/WKzXwPD4aZURrZwQvpdOt9fp58751eD0PIbVSJA6HSt6vJ1zbu+997ZYz+crr7zi9Us23RRFS1QBKJWKW2Gqir6GprxpioxzfirMhx9+6LWlUjUolK8pxXrs0nHvoSk24fesfieH6aaaJq7X6zANUu+rvv/+e69NU6n0uyFMy9fzG/dzrfv+xRdfFBk7l/jc6ffi5ZdfbnHVqlW9fi1btizy9cLqQvpbINlrQHH2N0r4edKqWOEyDfkirCKm1Yf1t2R47PR+ePjw4V5beL7jjJk2AAAAAAAAMcRDGwAAAAAAgBjioQ0AAAAAAEAM5dyaNlradOjQoRaHuYxa2vbhhx/22sLcU0QL8wabNGlicVieUNc12WuvvSy+9dZbvX4XX3yxxXoutKStc/66OGGur27rZ6JChQpeP93H8N+iOahaGlL33TnnPvjgA4sPOOAAry3X17TRY/aXv/zFa9tvv/0s1pzRGTNmeP2SXTdKc7HDv4l7nnY2hHns+rns1auX16Zj4rjjjrO4S5cuXj/Nk9fc/XAdE/0chOdC1xDQ9cJOPPFEr5+OMc7n/yR7LPT8h/nzyY4x/btwTRttS7RWA1Kn46h3795em37fJSolnOx6J4k+V/k8/qLKOYfb4f2C/l2ic6Cvoev+6ZpF4etpie+wLVW5fI4TrTuSjn+3nnv9Xgy/gxNdd6PWGQvXhGvWrJnF4bqBui7ckiVLLN68eXPke+n+FrXPcZLqvuk51rVf9LeFc84NHjzYYv3tUqVKFa9fWMo96r30uIfX5VTWRw0/x7reZz7R774XXnjBazv88MMt1nEZrvH40EMPWVya19Vkpg0AAAAAAEAM8dAGAAAAAAAghkp9elQ4Tf/888+3+JBDDrE4nP70wAMPWByWZkPywil/L774osVhmXU9HzrdMExZ0tSNZKeyhtMZdb/0vRKlboQpVu+++67Fzz77rMWffvqp10/TCErTNLt00HPXs2dPr02Pu5ZF19J7SJ9wLGopxHAsanlZPU/hNOBkyznruAqnpep+/OMf/7A4E1P+803UMUv1WOr04jD9Q6fw67UyLEOun6F8ux7uLE29bd26dWQ/HTv5Wvo1G8JxpNfYROkOicafjo8+ffpYvPvuu3v99Dpat25dr03HZqL9SLY8cS5ce/XfqilAie75Uv1363vpNa44pdj1NSpWrGhxu3btvH4tWrSw+Ntvv/XaJk2aZLGmSiVKH8+3a7L+2xcuXOi1vf322xZr+e9waQd9jTBlS6+/99xzj8WLFi2KfI1khZ+n4ny+ckm3bt0sbt++vdcWlZo/btw4r58uw5Fq2l2m0y6TwUwbAAAAAACAGOKhDQAAAAAAQAzx0AYAAAAAACCGSuWaNpoTfOihh3ptZ599tsWafzZz5kyv38iRIy3O1zzBdAjz+JYvX25xp06dvDYtzaZrbDRs2NDrV65cOYs1NzkstZ1ovQ3NWdTX+OGHH7x+um7N8OHDvTYt163rNqRSui+X6LjSMqVhrrTmX48fP97i8BwgMzZt2mRx9+7dvTYtm6jjMiwHGiW8Zq5YscJiXVfMOecmT55scZzLi8K5smXLWhyu8fX1119brGuqaDlO51jTprj0elqjRg2Lw3UVtMy3rquWiWOs+5QL652kSzqOhd7HaDnnROuJHXHEEV7b2LFjLdbPRaIS5eF9S67dx+h1qGbNmhaHx2TDhg0Wh9c4Pb+JSr9HrRFTnM+HrsWx7777Wty4cWOvn/5bwntevVfWz0+q6y3luvBa+eGHH1o8b948i5s2ber108/WhAkTvDZdK0W/I8O13lA8+lm/9tprLQ6vk/p51lLeZ555ptcvlXvPcF2/RGuJsaYNAAAAAABAHuOhDQAAAAAAQAyVyvQonTbcu3dvr61y5coWb9682eI777zT66epA0gfnSK2ZcsWr+21114rMk6VpnLoNFHnnNtzzz0t1ul0+plwzk/VYSp/8ek4GjVqlNemqVPPP/+8xake53ye1ruzwlKhmrq43377WXzqqad6/WrXrm2xTisPpwh/9tlnFpMCVXqE0/71Wjl16lSvTa+pOu6/++67yNfAjuk50GO8bt06r59e/3S8help6cC1NnP0HCcqIa4pqOF9i07TT7YMba6fUz0mtWrVsrhChQpevzVr1lj81VdfeW2aLpUo7UnPVarHNSrVIhz3lSpVsnj27Nlem34n678z/H1DSvp/hekuCxYssLh///4Wh0s2aArinDlzvLYff/wxnbuYt8L7Bk3pP/DAAyP/Tsfw8ccfb3E67kMTpZuW1PWUmTYAAAAAAAAxxEMbAAAAAACAGCo16VE6BbhDhw4Wd+7c2eun1S/Wrl1rsU4ndi73p4rmA52+Gk4fDreRPjp2NO3mkUceifwbPVfpqFrB+N05eg608tPtt99eEruDFKV7uu7WrVst1soazvnXVJ0SvnTpUq8f6XHFo2Nx/vz5Fg8aNMjrp1WHPv/8c4t16n6quJ5mj6aqzJgxw2K9d3XOT30J71+1Mk2i6qdxmM6fLXpNmjVrlsVhepQKj0nU8cpEpRg9bwsXLrT4oYce8vppaoh+JsJtvRdLxzUhF4VjRdPINNYUulCuj6Ns0nQ1rZzonHMDBgywWCtJhal+d911l8UbN25M6/6FFRz1/oj0KAAAAAAAABge2gAAAAAAAMQQD20AAAAAAABiqETXtElUqjBs07zU888/3+ImTZp4/aLK6K1fvz7l/QRQNM3r1Dx7AJm3s3nV4d/ruhC61lG4neh9yflPnebMT58+vQT3BJmi65DoukW1a9f2+lWrVs3i9957z2tL9rs2n8ai/lt1TZdE67uEvzOyebx0fRVdi0PXpnHOX78qLEWtv3f0NdKxbmA+y6dxU5J0/JUrV85ra9asmcW6pm24ps2TTz5pcbo/999//31aXy8dmGkDAAAAAAAQQzy0AQAAAAAAiKGsp0dp6a5wClqiKWk6japFixYW6/RA5/xyo5dffrnF4ZRDAADwP/odzBRxIP10Cv+qVassXr16tdePsZh52Tyuu+yyi7cdVao93KdffvnFYk2Vcs65qlWrFtkPKA10DCxfvtxrmzNnjsXt27e3eOTIkV6/devWZWjv4omZNgAAAAAAADHEQxsAAAAAAIAY4qENAAAAAABADGV9TZtUywJr3tr+++9vsa6RE74+Ze8AAAAQN6xbkz+i1rApzt+FrxGugwSUVroerXPOderUqYT2JN6YaQMAAAAAABBDPLQBAAAAAACIoeKmR61zzi3fYa8M07Snbdu2leCeZE3dNL5WLM5hnuI8ln6cw9zAeSz9OIe5gfNY+nEOcwPnsfTjHOaGIs9jAXm0AAAAAAAA8UN6FAAAAAAAQAzx0AYAAAAAACCGeGgDAAAAAAAQQzy0AQAAAAAAiCEe2gAAAAAAAMQQD20AAAAAAABiiIc2AAAAAAAAMcRDGwAAAAAAgBjioQ0AAAAAAEAM/X9qmyl8ptt89QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10  \n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gf6i5b0W8V2i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOnfjuIE8V5X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab09_Autoencoders.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
